{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d0ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c064d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #데이터 준비\n",
    "# (독립, 종속), (독립2, 종속2) = tf.keras.datasets.cifar10.load_data()\n",
    "# #print(독립.shape, 종속.shape)\n",
    "\n",
    "# 독립r = 독립.reshape(50000, 32, 32, 3)\n",
    "# 독립2r = 독립2.reshape(10000, 32, 32, 3)\n",
    "\n",
    "# # 종속 데이터를 1차원 배열로 변환\n",
    "# 종속 = pd.get_dummies(종속.ravel())\n",
    "# #print(종속)\n",
    "# # print(독립r.shape, 종속.shape)\n",
    "# # plt.imshow(독립2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c97af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(os.getcwd(), 'dataset', 'stones_png')\n",
    "label_names = os.listdir(dataset_path)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for label in label_names:\n",
    "    label_path = os.path.join(dataset_path, label)\n",
    "    if os.path.isdir(label_path):\n",
    "        image_files = os.listdir(label_path)\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(label_path,image_file)\n",
    "            images.append(image_path)\n",
    "            labels.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4936ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# dataset_path = os.path.join(os.getcwd(), 'dataset', 'stones_png')\n",
    "dataset_path = os.path.join(os.getcwd(), 'Dataset_JPG', 'Igneous')\n",
    "label_names = os.listdir(dataset_path)\n",
    "\n",
    "processed_images = []\n",
    "processed_labels = []\n",
    "\n",
    "targetX = 256\n",
    "targetY = 256\n",
    "target_size = (targetX, targetY)  # 목표 크기\n",
    "\n",
    "for label in label_names:\n",
    "    label_path = os.path.join(dataset_path, label)\n",
    "    if os.path.isdir(label_path):\n",
    "        image_files = os.listdir(label_path)\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(label_path, image_file)\n",
    "            try:\n",
    "                img = Image.open(image_path)\n",
    "                # 이미지 크기 조정 및 채널 변환\n",
    "                img = img.resize(target_size).convert('RGB')\n",
    "                # 이미지를 NumPy 배열로 변환하고 정규화\n",
    "                img_array = np.array(img) / 255.0\n",
    "                # 이미지 데이터와 라벨을 리스트에 추가\n",
    "                processed_images.append(img_array)\n",
    "                processed_labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "# NumPy 배열로 변환\n",
    "processed_images = np.array(processed_images)\n",
    "processed_labels = np.array(processed_labels)\n",
    "\n",
    "# 라벨을 숫자로 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(processed_labels)\n",
    "\n",
    "# 라벨을 원-핫 인코딩\n",
    "one_hot_labels = to_categorical(encoded_labels)\n",
    "\n",
    "독립 = processed_images\n",
    "종속 = one_hot_labels\n",
    "\n",
    "독립r = processed_images.reshape(len(processed_images), targetX, targetY, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b3ecc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#모델 만들기\n",
    "X = tf.keras.layers.Input(shape=[targetX, targetY, 3], name='input_layer')\n",
    "H = tf.keras.layers.Conv2D(3, kernel_size=5, activation='swish') (X)\n",
    "H = tf.keras.layers.Conv2D(6, kernel_size=5, activation='swish') (H)\n",
    "H = tf.keras.layers.Flatten() (H)\n",
    "H = tf.keras.layers.Dense(84, activation='swish') (H)\n",
    "Y = tf.keras.layers.Dense(2, activation='softmax') (H)\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e15fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(tf.__version__)\n",
    "tf.config.list_physical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# plt.imshow(독립[2])\n",
    "print(종속[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 학습하기\n",
    "model.fit(독립r, 종속, epochs=10)\n",
    "model.fit(독립r, 종속, epochs=50)\n",
    "\n",
    "#모델 구조 확인\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38499a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_list = []\n",
    "image_listR = []\n",
    "gray_image_list = []\n",
    "gray_image_listR = []\n",
    "inverted_gray_image_list = []\n",
    "inverted_gray_image_listR = []\n",
    "\n",
    "def ImageSetting(file_name, number):\n",
    "    # image_path = os.path.join(os.getcwd(), file_name)\n",
    "    image_path = glob.glob('./stones_reform/*/*.png')\n",
    "    image = Image.open(image_path)\n",
    "    gray_image = image.convert('L')\n",
    "    inverted_gray_image = ImageOps.invert(gray_image)\n",
    "    image_array = np.array(image)\n",
    "    gray_image_array = np.array(gray_image)\n",
    "    inverted_gray_image_array = np.array(inverted_gray_image)\n",
    "    image_arrayR = image_array.reshape(1, 784)\n",
    "    gray_image_arrayR = image_array.reshape(1, 784)\n",
    "    inverted_gray_image_arrayR = inverted_gray_image_array.reshape(1, 784)\n",
    "\n",
    "    image_list.insert(number, image_array)\n",
    "    image_listR.insert(number, image_arrayR)\n",
    "    gray_image_list.insert(number, gray_image_array)\n",
    "    gray_image_listR.insert(number, gray_image_arrayR)\n",
    "    inverted_gray_image_list.insert(number, inverted_gray_image_array)\n",
    "    inverted_gray_image_listR.insert(number, inverted_gray_image_arrayR)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = glob.glob('./')\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 이용\n",
    "loss, accuracy = model.evaluate(독립r, 종속)\n",
    "\n",
    "pred = model.predict(독립r[5:13])\n",
    "print(\"정확도: \",accuracy) #<--- 정확도 출력 방법 찾아보기\n",
    "pd.DataFrame(pred).round(2)\n",
    "plt.imshow(독립r[0])\n",
    "#print(\"값은: \", 종속)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d168e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장하기\n",
    "model.save('rock classification')\n",
    "\n",
    "# 모델 불러오기\n",
    "# loaded_model = load_model('mymodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e447b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(종속[0:100])\n",
    "plt.imshow(독립[2])\n",
    "#image_arrayR = image_array.reshape(3136, 784)\n",
    "#print(gray_image_array)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
